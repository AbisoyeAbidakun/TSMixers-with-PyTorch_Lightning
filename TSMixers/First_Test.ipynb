{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed22d354-43b7-4995-8bd7-16e7edd75adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4880d3-b697-4dc6-9bab-b1fe1791d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import  Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1510d9d6-2a40-4112-8b0f-b718fcaa3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464f2c65-d569-47b4-a699-4b8ab64cdc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'gs://time_series_datasets'\n",
    "LOCAL_CACHE_DIR = './data_loader/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1030fd16-e022-4e34-be30-4d0b3960ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"weather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0074f6-a846-4136-945f-df8d410ed29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type='MS'\n",
    "target='OT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7dc7c11-523f-4b70-bbdd-f9e9e0b00702",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_slice=slice(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6475f9a-93dd-4ef7-a54b-9019fc6dadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=int(336)\n",
    "pred_len=int(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f48c56e-813d-4420-bc9c-8c35c779cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(LOCAL_CACHE_DIR):\n",
    "    os.mkdir(LOCAL_CACHE_DIR)\n",
    "file_name = data + '.csv'\n",
    "cache_filepath = os.path.join(LOCAL_CACHE_DIR, file_name)\n",
    "if not os.path.isfile(cache_filepath):\n",
    "    tf.io.gfile.copy(\n",
    "  os.path.join(DATA_DIR, file_name), cache_filepath, overwrite=True\n",
    "  )\n",
    "    # Download the data from the cloud storage\n",
    "    # (Implement cloud storage download here)\n",
    "df_raw = pd.read_csv(cache_filepath)\n",
    "df = df_raw.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1dfbb2e-0011-4f18-9748-3c2bd951ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52696, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc8ec1a-10a5-4c7f-b958-e24370609f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_type == 'S':\n",
    "    df = df[[target]]\n",
    "elif feature_type == 'MS':\n",
    "    target_idx = df.columns.get_loc(target)\n",
    "    target_slice = slice(target_idx, target_idx + 1)\n",
    "# split train/valid/test\n",
    "n = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b34dd3a-d817-4dfd-b258-07b5de2c4b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(20, 21, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_slice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ecc2dcc-1f4e-480e-a490-35365b296850",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data.startswith('ETTm'):\n",
    "    train_end = 12 * 30 * 24 * 4\n",
    "    val_end = train_end + 4 * 30 * 24 * 4\n",
    "    test_end = val_end + 4 * 30 * 24 * 4\n",
    "elif data.startswith('ETTh'):\n",
    "     train_end = 12 * 30 * 24\n",
    "     val_end = train_end + 4 * 30 * 24\n",
    "     test_end = val_end + 4 * 30 * 24\n",
    "else:\n",
    "    train_end = int(n * 0.7)\n",
    "    val_end = n - int(n * 0.2)\n",
    "    test_end = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4faeb4ee-879d-43f2-9136-9afaa08049fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36887, 42157, 52696)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_end, val_end , test_end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca7067a2-b182-486b-a7d9-d9c73d3284bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:train_end]\n",
    "val_df = df[train_end - seq_len : val_end]\n",
    "test_df = df[val_end - seq_len : test_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49e1ba08-0028-4ea6-90bc-a2c6fb0ee644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>...</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "      <th>rain (mm)</th>\n",
       "      <th>raining (s)</th>\n",
       "      <th>SWDR (W/m�)</th>\n",
       "      <th>PAR (�mol/m�/s)</th>\n",
       "      <th>max. PAR (�mol/m�/s)</th>\n",
       "      <th>Tlog (degC)</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:10:00</th>\n",
       "      <td>1008.89</td>\n",
       "      <td>0.71</td>\n",
       "      <td>273.18</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>86.1</td>\n",
       "      <td>6.43</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.42</td>\n",
       "      <td>5.49</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.60</td>\n",
       "      <td>224.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.45</td>\n",
       "      <td>428.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:20:00</th>\n",
       "      <td>1008.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>273.22</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>85.2</td>\n",
       "      <td>6.45</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.39</td>\n",
       "      <td>5.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>206.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.51</td>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:30:00</th>\n",
       "      <td>1008.66</td>\n",
       "      <td>0.73</td>\n",
       "      <td>273.21</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>85.1</td>\n",
       "      <td>6.44</td>\n",
       "      <td>5.48</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.39</td>\n",
       "      <td>5.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.48</td>\n",
       "      <td>197.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.60</td>\n",
       "      <td>427.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:40:00</th>\n",
       "      <td>1008.64</td>\n",
       "      <td>0.37</td>\n",
       "      <td>272.86</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>86.3</td>\n",
       "      <td>6.27</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.35</td>\n",
       "      <td>5.37</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.48</td>\n",
       "      <td>206.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.70</td>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:50:00</th>\n",
       "      <td>1008.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>272.82</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>87.4</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.40</td>\n",
       "      <td>209.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.81</td>\n",
       "      <td>432.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
       "date                                                                     \n",
       "2020-01-01 00:10:00   1008.89      0.71    273.18        -1.33    86.1   \n",
       "2020-01-01 00:20:00   1008.76      0.75    273.22        -1.44    85.2   \n",
       "2020-01-01 00:30:00   1008.66      0.73    273.21        -1.48    85.1   \n",
       "2020-01-01 00:40:00   1008.64      0.37    272.86        -1.64    86.3   \n",
       "2020-01-01 00:50:00   1008.61      0.33    272.82        -1.50    87.4   \n",
       "\n",
       "                     VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  \\\n",
       "date                                                                       \n",
       "2020-01-01 00:10:00          6.43          5.54          0.89       3.42   \n",
       "2020-01-01 00:20:00          6.45          5.49          0.95       3.39   \n",
       "2020-01-01 00:30:00          6.44          5.48          0.96       3.39   \n",
       "2020-01-01 00:40:00          6.27          5.41          0.86       3.35   \n",
       "2020-01-01 00:50:00          6.26          5.47          0.79       3.38   \n",
       "\n",
       "                     H2OC (mmol/mol)  ...  wv (m/s)  max. wv (m/s)  wd (deg)  \\\n",
       "date                                  ...                                      \n",
       "2020-01-01 00:10:00             5.49  ...      1.02           1.60     224.3   \n",
       "2020-01-01 00:20:00             5.45  ...      0.43           0.84     206.8   \n",
       "2020-01-01 00:30:00             5.43  ...      0.61           1.48     197.1   \n",
       "2020-01-01 00:40:00             5.37  ...      1.11           1.48     206.4   \n",
       "2020-01-01 00:50:00             5.42  ...      0.49           1.40     209.6   \n",
       "\n",
       "                     rain (mm)  raining (s)  SWDR (W/m�)  PAR (�mol/m�/s)  \\\n",
       "date                                                                        \n",
       "2020-01-01 00:10:00        0.0          0.0          0.0              0.0   \n",
       "2020-01-01 00:20:00        0.0          0.0          0.0              0.0   \n",
       "2020-01-01 00:30:00        0.0          0.0          0.0              0.0   \n",
       "2020-01-01 00:40:00        0.0          0.0          0.0              0.0   \n",
       "2020-01-01 00:50:00        0.0          0.0          0.0              0.0   \n",
       "\n",
       "                     max. PAR (�mol/m�/s)  Tlog (degC)     OT  \n",
       "date                                                           \n",
       "2020-01-01 00:10:00                   0.0        11.45  428.1  \n",
       "2020-01-01 00:20:00                   0.0        11.51  428.0  \n",
       "2020-01-01 00:30:00                   0.0        11.60  427.6  \n",
       "2020-01-01 00:40:00                   0.0        11.70  430.0  \n",
       "2020-01-01 00:50:00                   0.0        11.81  432.2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "866d6973-9729-4507-b272-e49494125786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d8662c-dd61-4235-a555-a148b5527df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(df, scaler):\n",
    "    data = scaler.transform(df.values)\n",
    "    return pd.DataFrame(data, index=df.index, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b6c1c39-a388-4b4a-889f-98a27acc9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = scale_df(train_df, scaler)\n",
    "val_df = scale_df(val_df, scaler)\n",
    "test_df = scale_df(test_df, scaler)\n",
    "n_feature = train_df.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e8e234d-e457-46e9-9f35-e28d8b413c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_window(data):\n",
    "    inputs = data[:, :seq_len]\n",
    "    labels = data[:, seq_len: ]\n",
    "    inputs.set_shape([None, seq_len, None])\n",
    "    labels.set_shape([None, pred_len, None])\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd9f0370-d591-4d53-a550-ec753a5b9e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_dataloader(data, shuffle=True):\n",
    "    inputs, labels =_split_window(data)\n",
    "    input_data = np.array(inputs, dtype=np.float32)\n",
    "    input_dataset = torch.tensor(input_data)\n",
    "    label_data = np.array(labels, dtype=np.float32)\n",
    "    label_dataset = torch.tensor(label_data)\n",
    "    input = DataLoader(input_dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
    "    label = DataLoader(label_dataset , batch_size=self.batch_size, shuffle=shuffle)\n",
    "    #return DataLoader(dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
    "    return input , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a4ed8-cf3e-4e8e-9d70-676a4593f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __len__():\n",
    "    return len(data) - (seq_len + pred_len) + 1\n",
    "\n",
    "def __getitem__(idx):\n",
    "    idx += seq_len  # Adjust index to consider the sequence length\n",
    "    data_window = data[idx - seq_len: idx + pred_len]\n",
    "    inputs = data_window[:seq_len, :]\n",
    "    labels = data_window[seq_len:, target_slice]\n",
    "    return torch.tensor(inputs, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "595646c3-e6c4-4ad0-8aec-622a6ea1e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDataset(Dataset):\n",
    "    def __init__(self, data, seq_len, pred_len, feature_type, target='OT'):\n",
    "        self.data = 'weather'\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.feature_type = feature_type\n",
    "        self.target = target\n",
    "        self.target_slice = slice(0, None)\n",
    "        self._read_data()\n",
    "\n",
    "    def _read_data(self):\n",
    "        if not os.path.isdir(LOCAL_CACHE_DIR):\n",
    "            os.mkdir(LOCAL_CACHE_DIR)\n",
    "        file_name = f'{self.data}.csv'\n",
    "        cache_filepath = os.path.join(LOCAL_CACHE_DIR, file_name)\n",
    "        if not os.path.isfile(cache_filepath):\n",
    "            # Copy data from cloud storage if not exists locally\n",
    "            pass  # Add code for copying data from DATA_DIR to LOCAL_CACHE_DIR here\n",
    "\n",
    "        df_raw = pd.read_csv(cache_filepath)\n",
    "        df = df_raw.set_index('date')\n",
    "        if self.feature_type == 'S':\n",
    "            df = df[[self.target]]\n",
    "        elif self.feature_type == 'MS':\n",
    "            target_idx = df.columns.get_loc(self.target)\n",
    "            self.target_slice = slice(target_idx, target_idx + 1)\n",
    "\n",
    "        n = len(df)\n",
    "        if self.data.startswith('ETTm'):\n",
    "            train_end = 12 * 30 * 24 * 4\n",
    "            val_end = train_end + 4 * 30 * 24 * 4\n",
    "            test_end = val_end + 4 * 30 * 24 * 4\n",
    "        elif self.data.startswith('ETTh'):\n",
    "            train_end = 12 * 30 * 24\n",
    "            val_end = train_end + 4 * 30 * 24\n",
    "            test_end = val_end + 4 * 30 * 24\n",
    "        else:\n",
    "            train_end = int(n * 0.7)\n",
    "            val_end = n - int(n * 0.2)\n",
    "            test_end = n\n",
    "        train_df = df[:train_end]\n",
    "        val_df = df[train_end - self.seq_len: val_end]\n",
    "        test_df = df[val_end - self.seq_len: test_end]\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(train_df.values)\n",
    "\n",
    "        self.train_data = self.scale_df(train_df)\n",
    "        self.val_data = self.scale_df(val_df)\n",
    "        self.test_data = self.scale_df(test_df)\n",
    "        self.n_feature = self.train_data.shape[-1]\n",
    "\n",
    "        return self.train_data, self.val_data, self.test_data, self.n_feature \n",
    "\n",
    "    def scale_df(self, df):\n",
    "        data = self.scaler.transform(df.values)\n",
    "        return pd.DataFrame(data, index=df.index, columns=df.columns)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - (self.seq_len + self.pred_len) + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.seq_len  # Adjust index to consider the sequence length\n",
    "        data_window = self.data[idx - self.seq_len: idx + self.pred_len]\n",
    "        inputs = data_window[:self.seq_len, :]\n",
    "        labels = data_window[self.seq_len:, self.target_slice]\n",
    "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "160c4ac6-dcdc-4f58-8e3e-71ecd7cd4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data, batch_size, seq_len, pred_len, feature_type, target='OT'):\n",
    "        super(TSDataModule, self).__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.feature_type = feature_type\n",
    "        self.target = target\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset, self.val_dataset, self.test_data, self.n_feature = TSDataset(self.data, self.seq_len, self.pred_len, self.feature_type, self.target)._read_data()\n",
    "        #self.val_dataset = TSDataset(self.data.val_df.values, self.seq_len, self.pred_len, self.feature_type, self.target)\n",
    "        #self.test_dataset = TSDataset(self.data.test_df.values, self.seq_len, self.pred_len, self.feature_type, self.target)\n",
    "        #self.n_feature = self.train_dataset.n_feature\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06c6292f-ab2b-4702-8703-647c9c822260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from torchmetrics import Metric\n",
    "\n",
    "\n",
    "class MyAccuracy(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"correct\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds, target):\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        assert preds.shape == target.shape\n",
    "        self.correct += torch.sum(preds == target)\n",
    "        self.total += target.numel()\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct.float() / self.total.float()\n",
    "\n",
    "\n",
    "class NN(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=num_classes\n",
    "        )\n",
    "        self.my_accuracy = MyAccuracy()\n",
    "        self.f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        accuracy = self.my_accuracy(scores, y)\n",
    "        f1_score = self.f1_score(scores, y)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"train_loss\": loss,\n",
    "                \"train_accuracy\": accuracy,\n",
    "                \"train_f1_score\": f1_score,\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return {\"loss\": loss, \"scores\": scores, \"y\": y}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x)\n",
    "        loss = self.loss_fn(scores, y)\n",
    "        return loss, scores, y\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x)\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b9a602d-e153-44a3-bc1d-61742c344a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 21\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18565aae-651b-4a18-b457-3f67b788ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TSDataModule\n",
    "data_module = TSDataModule(data='weather',  # Replace with your actual data object\n",
    "                           batch_size=32,\n",
    "                           seq_len=int(336),\n",
    "                           pred_len=int(96),\n",
    "                           feature_type='MS',  # Replace with 'S' or 'MS' based on your data\n",
    "                           target='OT')  # Replace with your target feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acb430fc-ad12-4d2b-a0ed-2b0f40fff3d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TSDataModule' object has no attribute 'train_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m td \u001b[38;5;241m=\u001b[39m \u001b[43mdata_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[59], line 18\u001b[0m, in \u001b[0;36mTSDataModule.train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataLoader(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TSDataModule' object has no attribute 'train_dataset'"
     ]
    }
   ],
   "source": [
    "td = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85e3cc10-d8ae-42fa-b844-db3424a55ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size=input_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e724a119-1df3-4bb3-b5e5-4cfc938d49fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abidakunabisoye/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/lightning_fabric/connector.py:565: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "/Users/abidakunabisoye/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:125: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\", devices=1, min_epochs=1, max_epochs=3, precision=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9fe3153b-b559-4ede-a51e-b503d346806b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mvalidate(model, datamodule\u001b[38;5;241m=\u001b[39mdata_module)\n\u001b[1;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(model, datamodule\u001b[38;5;241m=\u001b[39mdata_module)\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    577\u001b[0m     ckpt_path,\n\u001b[1;32m    578\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    580\u001b[0m )\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:951\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39msetup_environment()\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__setup_profiler()\n\u001b[0;32m--> 951\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_setup_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# check if we should delay restoring checkpoint till later\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mrestore_checkpoint_after_setup:\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:92\u001b[0m, in \u001b[0;36m_call_setup_hook\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     89\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_setup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mdatamodule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[43m_call_lightning_datamodule_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msetup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m _call_callback_hooks(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, stage\u001b[38;5;241m=\u001b[39mfn)\n\u001b[1;32m     94\u001b[0m _call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, stage\u001b[38;5;241m=\u001b[39mfn)\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:179\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningDataModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mTSDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_feature \u001b[38;5;241m=\u001b[39m TSDataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)\n",
      "Cell \u001b[0;32mIn[36], line 65\u001b[0m, in \u001b[0;36mTSDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len  \u001b[38;5;66;03m# Adjust index to consider the sequence length\u001b[39;00m\n\u001b[1;32m     64\u001b[0m data_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len: idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len]\n\u001b[0;32m---> 65\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mdata_window\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     66\u001b[0m labels \u001b[38;5;241m=\u001b[39m data_window[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_slice]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(inputs, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module)\n",
    "trainer.validate(model, datamodule=data_module)\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1dc5bc3-adb4-453b-bd96-970d14fa68e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `YourModel`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Use the trained model for predictions\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Example: Get test data loader and make predictions\u001b[39;00m\n\u001b[1;32m      6\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m data_module\u001b[38;5;241m.\u001b[39mtest_dataloader()\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:749\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    746\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer.test()` requires a `LightningModule` when it hasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt been passed in a previous run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    747\u001b[0m         )\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 749\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_unwrap_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    751\u001b[0m _verify_strategy_supports_compile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/utilities/compile.py:131\u001b[0m, in \u001b[0;36m_maybe_unwrap_optimized\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m    130\u001b[0m _check_mixed_imports(model)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `YourModel`"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Test the model\n",
    "trainer.test(model, datamodule=data_module)\n",
    "\n",
    "# Use the trained model for predictions\n",
    "# Example: Get test data loader and make predictions\n",
    "test_dataloader = data_module.test_dataloader()\n",
    "predictions = []\n",
    "for batch in test_dataloader:\n",
    "    inputs, _ = batch\n",
    "    predictions_batch = model(inputs)\n",
    "    predictions.append(predictions_batch.detach().cpu().numpy())\n",
    "\n",
    "# Concatenate predictions into a numpy array\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6921736e-ccca-495c-8067-097fcac9c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as geek \n",
    "  \n",
    "  \n",
    "x = geek.constant([[[ 1, 2, 3], \n",
    "                    [ 4, 5, 6]], \n",
    "                   [[ 7, 8, 9], \n",
    "                    [ 10, 11, 12]], \n",
    "                   [[ 13, 14, 15], \n",
    "                    [ 16, 17, 18]], \n",
    "                   [[ 19, 20, 21], \n",
    "                    [ 22, 23, 24]]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d1d9d91-9888-48c9-a5c5-ae44fb8ad738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 2, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "387a5888-83a4-4de6-b54e-0dfc09ee532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_tensor = geek.transpose(x, perm = [0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa306878-f5fc-4b5d-8bf6-2d6f74159533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([4, 3, 2]), 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed_tensor.shape, transposed_tensor.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79f70f4e-d3f1-4c3d-a98c-46dec0e4efb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 2), dtype=int32, numpy=\n",
       "array([[[ 1,  4],\n",
       "        [ 2,  5],\n",
       "        [ 3,  6]],\n",
       "\n",
       "       [[ 7, 10],\n",
       "        [ 8, 11],\n",
       "        [ 9, 12]],\n",
       "\n",
       "       [[13, 16],\n",
       "        [14, 17],\n",
       "        [15, 18]],\n",
       "\n",
       "       [[19, 22],\n",
       "        [20, 23],\n",
       "        [21, 24]]], dtype=int32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4327c300-896f-4ef2-b652-b78460c5326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Input Tensor:\n",
      "[[[0.47514888 0.47613429 0.93765199 0.79252459 0.63574814 0.12671022\n",
      "   0.48848839 0.98890659 0.19326399 0.66808064]\n",
      "  [0.15818084 0.28068655 0.32338139 0.82462328 0.85483169 0.18806031\n",
      "   0.79114297 0.36286764 0.17001837 0.86611145]\n",
      "  [0.48137374 0.06788061 0.01775989 0.47398271 0.78528897 0.1472132\n",
      "   0.11111811 0.88943838 0.41352883 0.63053788]]\n",
      "\n",
      " [[0.91967109 0.36178371 0.6083693  0.43405874 0.74289473 0.74715923\n",
      "   0.64159177 0.79346753 0.41659555 0.50756065]\n",
      "  [0.58041969 0.57648182 0.80107985 0.30507917 0.74441683 0.04015197\n",
      "   0.3019863  0.30614458 0.32898332 0.71063726]\n",
      "  [0.76552368 0.11061252 0.02050674 0.79833809 0.02673619 0.76268763\n",
      "   0.69708581 0.51955096 0.92430361 0.48559953]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(2, 3, 10)\n",
    "print(\"Original Input Tensor:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00e47847-7b31-4e17-a625-bf3a00f5881d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transposed Input Tensor:\n",
      "[[[0.47514888 0.15818084 0.48137374]\n",
      "  [0.47613429 0.28068655 0.06788061]\n",
      "  [0.93765199 0.32338139 0.01775989]\n",
      "  [0.79252459 0.82462328 0.47398271]\n",
      "  [0.63574814 0.85483169 0.78528897]\n",
      "  [0.12671022 0.18806031 0.1472132 ]\n",
      "  [0.48848839 0.79114297 0.11111811]\n",
      "  [0.98890659 0.36286764 0.88943838]\n",
      "  [0.19326399 0.17001837 0.41352883]\n",
      "  [0.66808064 0.86611145 0.63053788]]\n",
      "\n",
      " [[0.91967109 0.58041969 0.76552368]\n",
      "  [0.36178371 0.57648182 0.11061252]\n",
      "  [0.6083693  0.80107985 0.02050674]\n",
      "  [0.43405874 0.30507917 0.79833809]\n",
      "  [0.74289473 0.74441683 0.02673619]\n",
      "  [0.74715923 0.04015197 0.76268763]\n",
      "  [0.64159177 0.3019863  0.69708581]\n",
      "  [0.79346753 0.30614458 0.51955096]\n",
      "  [0.41659555 0.32898332 0.92430361]\n",
      "  [0.50756065 0.71063726 0.48559953]]]\n"
     ]
    }
   ],
   "source": [
    "# Transpose the input tensor for processing in the model\n",
    "x_transposed = np.transpose(x, (0, 2, 1))  # [Batch, Input Length, Channel]\n",
    "print(\"\\nTransposed Input Tensor:\")\n",
    "print(x_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4dbf5076-2a46-452b-b75c-40c8d8fed31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply target slicing to select channels 1 and 2\n",
    "target_slice = slice(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2fb19b6c-016a-4dc0-ae54-3183491f9f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(1, 3, None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_slice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef68cede-a256-4402-a24c-f4d838c150ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_output = x_transposed[:, :, target_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84399c49-9de2-4631-9e67-0103e02e5123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sliced Output Tensor (Channels 1 and 2):\n",
      "[[[0.15818084 0.48137374]\n",
      "  [0.28068655 0.06788061]\n",
      "  [0.32338139 0.01775989]\n",
      "  [0.82462328 0.47398271]\n",
      "  [0.85483169 0.78528897]\n",
      "  [0.18806031 0.1472132 ]\n",
      "  [0.79114297 0.11111811]\n",
      "  [0.36286764 0.88943838]\n",
      "  [0.17001837 0.41352883]\n",
      "  [0.86611145 0.63053788]]\n",
      "\n",
      " [[0.58041969 0.76552368]\n",
      "  [0.57648182 0.11061252]\n",
      "  [0.80107985 0.02050674]\n",
      "  [0.30507917 0.79833809]\n",
      "  [0.74441683 0.02673619]\n",
      "  [0.04015197 0.76268763]\n",
      "  [0.3019863  0.69708581]\n",
      "  [0.30614458 0.51955096]\n",
      "  [0.32898332 0.92430361]\n",
      "  [0.71063726 0.48559953]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSliced Output Tensor (Channels 1 and 2):\")\n",
    "print(sliced_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ce6f84a-ac61-40ab-b10a-0e4d210bbc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.47514888 0.15818084 0.48137374]\n",
      "  [0.47613429 0.28068655 0.06788061]\n",
      "  [0.93765199 0.32338139 0.01775989]\n",
      "  [0.79252459 0.82462328 0.47398271]\n",
      "  [0.63574814 0.85483169 0.78528897]\n",
      "  [0.12671022 0.18806031 0.1472132 ]\n",
      "  [0.48848839 0.79114297 0.11111811]\n",
      "  [0.98890659 0.36286764 0.88943838]\n",
      "  [0.19326399 0.17001837 0.41352883]\n",
      "  [0.66808064 0.86611145 0.63053788]]\n",
      "\n",
      " [[0.91967109 0.58041969 0.76552368]\n",
      "  [0.36178371 0.57648182 0.11061252]\n",
      "  [0.6083693  0.80107985 0.02050674]\n",
      "  [0.43405874 0.30507917 0.79833809]\n",
      "  [0.74289473 0.74441683 0.02673619]\n",
      "  [0.74715923 0.04015197 0.76268763]\n",
      "  [0.64159177 0.3019863  0.69708581]\n",
      "  [0.79346753 0.30614458 0.51955096]\n",
      "  [0.41659555 0.32898332 0.92430361]\n",
      "  [0.50756065 0.71063726 0.48559953]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05dc8c2a-7cc1-479f-b369-0a89c0115de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_output_transposed = np.transpose(sliced_output, (0, 2, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0fb91b27-79fc-4d3f-8755-65437bfaa07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.15818084 0.28068655 0.32338139 0.82462328 0.85483169 0.18806031\n",
      "   0.79114297 0.36286764 0.17001837 0.86611145]\n",
      "  [0.48137374 0.06788061 0.01775989 0.47398271 0.78528897 0.1472132\n",
      "   0.11111811 0.88943838 0.41352883 0.63053788]]\n",
      "\n",
      " [[0.58041969 0.57648182 0.80107985 0.30507917 0.74441683 0.04015197\n",
      "   0.3019863  0.30614458 0.32898332 0.71063726]\n",
      "  [0.76552368 0.11061252 0.02050674 0.79833809 0.02673619 0.76268763\n",
      "   0.69708581 0.51955096 0.92430361 0.48559953]]]\n"
     ]
    }
   ],
   "source": [
    "print(sliced_output_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd2840-b615-4b0b-a917-541fe28123c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
