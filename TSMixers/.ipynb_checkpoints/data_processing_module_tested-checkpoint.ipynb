{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080126be-5fc8-412e-8794-5d932044da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558a3935-5036-48a9-ad36-0f330930b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'gs://time_series_datasets'\n",
    "LOCAL_CACHE_DIR = './data_loader/dataset/'\n",
    "\n",
    "# modularise the code \n",
    "class TSFDataLoader:\n",
    "  \"\"\"Generate data loader from raw data.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self, data_dir, data,seq_len, pred_len, feature_type, target='OT'\n",
    "  ):\n",
    "    self.data_dir = data_dir\n",
    "    self.data = data\n",
    "    #self.batch_size = batch_size\n",
    "    self.seq_len = seq_len\n",
    "    self.pred_len = pred_len\n",
    "    self.feature_type = feature_type\n",
    "    self.target = target\n",
    "    #self.target_slice = slice(0, None)\n",
    "\n",
    "    self.train_df, self.val_df, self.test_df = self._read_data()\n",
    "\n",
    "  def _read_data(self):\n",
    "    \"\"\"Load raw data and split datasets.\"\"\"\n",
    "\n",
    "    # copy data from cloud storage if not exists\n",
    "    LOCAL_CACHE_DIR = self.data_dir\n",
    "    if not os.path.isdir(LOCAL_CACHE_DIR):\n",
    "      os.mkdir(LOCAL_CACHE_DIR)\n",
    "\n",
    "    file_name = self.data + '.csv'\n",
    "    cache_filepath = os.path.join(LOCAL_CACHE_DIR, file_name)\n",
    "    if not os.path.isfile(cache_filepath):\n",
    "      tf.io.gfile.copy(\n",
    "          os.path.join(DATA_DIR, file_name), cache_filepath, overwrite=True\n",
    "      )\n",
    "\n",
    "    df_raw = pd.read_csv(cache_filepath)\n",
    "\n",
    "    # S: univariate-univariate, M: multivariate-multivariate, MS:\n",
    "    # multivariate-univariate\n",
    "    df = df_raw.set_index('date')\n",
    "    if self.feature_type == 'S':\n",
    "      df = df[[self.target]]\n",
    "    # elif self.feature_type == 'MS':\n",
    "    # target_idx = df.columns.get_loc(self.target)\n",
    "    # self.target_slice = slice(target_idx, target_idx + 1)\n",
    "\n",
    "    # split train/valid/test\n",
    "    n = len(df)\n",
    "    if self.data.startswith('ETTm'):\n",
    "      train_end = 12 * 30 * 24 * 4\n",
    "      val_end = train_end + 4 * 30 * 24 * 4\n",
    "      test_end = val_end + 4 * 30 * 24 * 4\n",
    "    elif self.data.startswith('ETTh'):\n",
    "      train_end = 12 * 30 * 24\n",
    "      val_end = train_end + 4 * 30 * 24\n",
    "      test_end = val_end + 4 * 30 * 24\n",
    "    else:\n",
    "      train_end = int(n * 0.7)\n",
    "      val_end = n - int(n * 0.2)\n",
    "      test_end = n\n",
    "    train_df = df[:train_end]\n",
    "    val_df = df[train_end - self.seq_len : val_end]\n",
    "    test_df = df[val_end - self.seq_len : test_end]\n",
    "\n",
    "    # standardize by training set\n",
    "    self.scaler = StandardScaler()\n",
    "    self.scaler.fit(train_df.values)\n",
    "\n",
    "    def scale_df(df, scaler):\n",
    "      data = scaler.transform(df.values)\n",
    "      return pd.DataFrame(data, index=df.index, columns=df.columns)\n",
    "\n",
    "    train_df = scale_df(train_df, self.scaler)\n",
    "    val_df = scale_df(val_df, self.scaler)\n",
    "    test_df = scale_df(test_df, self.scaler)\n",
    "    #self.n_feature = self.train_df.shape[-1]\n",
    "\n",
    "    return train_df, val_df, test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e7ef78-5598-4ed8-94e6-f946fc35eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DIR = 'gs://time_series_datasets'\n",
    "#LOCAL_CACHE_DIR = './data_loader/dataset/'\n",
    "\n",
    "class DataExtractor:\n",
    "    def __init__(self, df, row_length=432, tail_length=96):\n",
    "        self.data = self.extract_contiguous_rows_with_stride(df, row_length, tail_length)\n",
    "\n",
    "\n",
    "    def extract_contiguous_rows_with_stride(self, df, row_length=432, tail_length=96):\n",
    "        num_rows = len(df)\n",
    "        num_chunks = num_rows - row_length + 1\n",
    "\n",
    "        contiguous_rows = []\n",
    "        last_four_rows = []\n",
    "        indices = []\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            chunk = df.iloc[i:i+row_length].values\n",
    "            contiguous_rows.append(chunk[:row_length-tail_length])\n",
    "            last_four_rows.append(chunk[-tail_length:])\n",
    "            indices.append(i)  # Adding the index\n",
    "\n",
    "        data = {\n",
    "            \"inputs\": np.array(contiguous_rows),\n",
    "            \"labels\": np.array(last_four_rows),\n",
    "            \"indices\": np.array(indices)\n",
    "        }\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"indices\"])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = self.data[\"indices\"][index]\n",
    "        return {\n",
    "            \"inputs\": self.data[\"inputs\"][idx],\n",
    "            \"labels\": self.data[\"labels\"][idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b9a281-1808-4fa7-864d-223473267b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_extractor):\n",
    "        self.data_extractor = data_extractor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_extractor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data_extractor[index]\n",
    "        inputs = torch.tensor(data[\"inputs\"], dtype=torch.float32)\n",
    "        labels = torch.tensor(data[\"labels\"], dtype=torch.float32)\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0693481-8934-4cd3-9beb-bb60fd2d1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, val_df, test_df, batch_size=32):\n",
    "        super(CustomDataModule, self).__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Initialize datasets\n",
    "        self.train_dataset = CustomDataset(self.train_df)\n",
    "        self.val_dataset = CustomDataset(self.val_df)\n",
    "        self.test_dataset = CustomDataset(self.test_df)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32d34f2-c384-404a-9131-a7b6e6255880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Creating a sample train, validation and test DataFrame from the weather data\n",
    "ts_weather = TSFDataLoader(data_dir='./data_loader/dataset/', data='weather', seq_len=432, pred_len=96, feature_type='MS', target='OT')\n",
    "train_df, val_df, test_df = ts_weather._read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9226f1d3-2f95-4c0b-943e-239470a50673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36887, 21), (5702, 21), (10971, 21))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f6d89b-90ed-4f50-841c-32ee40108f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataExtractor instance\n",
    "train_data = DataExtractor(train_df)\n",
    "val_data = DataExtractor(val_df)\n",
    "test_dat = DataExtractor(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09964712-77e4-41bf-9102-794025121e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a LightningDataModule instance\n",
    "#data_module = CustomDataModule(data_extractor)\n",
    "data_module_01= CustomDataModule(train_data, val_data, test_dat, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8a238c-fe81-43f3-8394-ec3184e89667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6014ba9a-4825-430a-b064-063b5a1029df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, input_dim, norm_type, activation, dropout, ff_dim):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.norm = nn.LayerNorm(input_dim) if norm_type == 'L' else nn.BatchNorm1d(input_dim)\n",
    "        self.temporal_linear = nn.Sequential(\n",
    "            nn.Linear(input_dim, 336),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.feature_linear = nn.Sequential(\n",
    "            nn.Linear(input_dim, ff_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, input_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.size(1), x.size(2),self.input_dim) #21, 336, 21\n",
    "        assert x.size(-1) == self.input_dim, f\"Input tensor last dimension {x.size(-1)} does not match expected input features {self.input_dim}\"\n",
    "        res = x\n",
    "        x = self.norm(x)\n",
    "        print(x.size(-1), x.size(1))\n",
    "        x = self.temporal_linear(x.transpose(1, 2)).transpose(1, 2)\n",
    "        x = x + res\n",
    "        x = self.norm(x)\n",
    "        x = self.feature_linear(x)\n",
    "        x = x + res\n",
    "        return x\n",
    "        \n",
    "# Lambda layer for custom operations\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super(Lambda, self).__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "910a611d-bf3e-411c-9792-a83b0abaa010",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Reversible Instance Normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, axis, eps=1e-5, affine=True):\n",
    "        \"\"\"\n",
    "        Constructor for RevNorm.\n",
    "\n",
    "        Args:\n",
    "            axis (int): Axis or axes along which to compute mean and variance.\n",
    "            eps (float): Small constant to avoid division by zero.\n",
    "            affine (bool): If True, learnable affine parameters are applied.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.axis = axis\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "\n",
    "        if self.affine:\n",
    "            self.affine_weight = nn.Parameter(torch.ones(1))\n",
    "            self.affine_bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x, mode, target_slice=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the RevNorm layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "            mode (str): 'norm' for normalization, 'denorm' for denormalization.\n",
    "            target_slice (int): Target slice index for denormalization.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Normalized or denormalized tensor.\n",
    "        \"\"\"\n",
    "        if mode == 'norm':\n",
    "            self._get_statistics(x)\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x, target_slice)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return x\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        \"\"\"\n",
    "        Calculate mean and standard deviation of the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        \"\"\"\n",
    "        self.mean = torch.mean(x, dim=self.axis, keepdim=True).detach()\n",
    "        self.stdev = torch.sqrt(torch.var(x, dim=self.axis, keepdim=True) + self.eps).detach()\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        \"\"\"\n",
    "        Normalize the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Normalized tensor.\n",
    "        \"\"\"\n",
    "        x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight\n",
    "            x = x + self.affine_bias\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x, target_slice=None):\n",
    "        \"\"\"\n",
    "        Denormalize the input te nsor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "            target_slice (int): Target slice index for denormalization.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Denormalized tensor.\n",
    "        \"\"\"\n",
    "        if self.affine:\n",
    "            x = x - self.affine_bias\n",
    "            x = x / self.affine_weight\n",
    "        x = x * self.stdev[:, :, target_slice]\n",
    "        x = x + self.mean[:, :, target_slice]\n",
    "        return x\n",
    "\n",
    "class RevNormLightning(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning module for RevNorm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, axis, eps=1e-5, affine=True):\n",
    "        \"\"\"\n",
    "        Constructor for RevNormLightning.\n",
    "\n",
    "        Args:\n",
    "            axis (int): Axis or axes along which to compute mean and variance.\n",
    "            eps (float): Small constant to avoid division by zero.\n",
    "            affine (bool): If True, learnable affine parameters are applied.\n",
    "        \"\"\"\n",
    "        super(RevNormLightning, self).__init__()\n",
    "        self.revnorm = RevNorm(axis, eps, affine)\n",
    "\n",
    "    def forward(self, x, mode, target_slice=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the RevNormLightning model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "            mode (str): 'norm' for normalization, 'denorm' for denormalization.\n",
    "            target_slice (int): Target slice index for denormalization.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Normalized or denormalized tensor.\n",
    "        \"\"\"\n",
    "        return self.revnorm(x, mode, target_slice)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure optimizer for training.\n",
    "        \"\"\"\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ee26f03b-116d-46af-bed7-453a7ca2d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#developing the whole pipeline: \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "    \n",
    "class TSMixer(pl.LightningModule):\n",
    "    \"\"\"\n",
    "        Constructor for TSMixer.\n",
    "        \n",
    "        Args:\n",
    "            input_shape (tuple): Input tensor shape.\n",
    "            pred_len (int): Length of the prediction.\n",
    "            norm_type (str): Type of normalization ('L' for LayerNorm, 'B' for BatchNorm).\n",
    "            activation (nn.Module): Activation function.\n",
    "            n_block (int): Number of ResBlocks in TSMixer.\n",
    "            dropout (float): Dropout probability.\n",
    "            ff_dim (int): Feature dimension.\n",
    "            target_slice (int): Target slice index.\n",
    "            rev_norm_inst(bool): Flag for reverse normalisation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape, pred_len, norm_type, activation, n_block, dropout, ff_dim, rev_norm_inst=False, target_slice=None):\n",
    "        super(TSMixer, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.pred_len = pred_len\n",
    "        self.target_slice = target_slice\n",
    "        self.activation = activation\n",
    "        self.n_block = n_block\n",
    "\n",
    "        self.rev_norm_inst = rev_norm_inst\n",
    "        if self.rev_norm_inst:\n",
    "              self.rev_norm = RevNormLightning(axis=-2)\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(self.n_block):\n",
    "            layers.append(ResBlock(self.input_shape[-1], norm_type, activation, dropout, ff_dim))\n",
    "        self.blocks = nn.Sequential(*layers)\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(self.input_shape[-1], self.pred_len),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the TSMixer model.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "            mode (str): 'norm' for training, 'denorm' for inference.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through the TSMixer.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.rev_norm_inst:\n",
    "               x = self.rev_norm(x, mode='norm')\n",
    "        x = self.blocks(x)\n",
    "        if self.target_slice:\n",
    "            x = x[:, :, self.target_slice]\n",
    "        x = x.transpose(1, 2) # [Batch, Channel, Input Length]\n",
    "        x = self.output_layer(x) # [Batch, Channel, Output Length]\n",
    "        x = x.transpose(1, 2) # [Batch, Output Length, Channel]\n",
    "        outputs = x\n",
    "        if self.rev_norm_inst:\n",
    "          outputs = self.rev_norm(x, 'denorm', self.target_slice)\n",
    "        return outputs\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        target_ = y.unsqueeze(dim=-1)\n",
    "        loss = nn.MSELoss()(y_hat, target_)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        target_ = y.unsqueeze(dim=-1)\n",
    "        loss = nn.MSELoss()(y_hat, target_)\n",
    "        #loss = nn.MSELoss()(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dcc1b54d-a46c-4b45-a193-7385d89389ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSMixer(\n",
    "                input_shape=(336,21),\n",
    "                pred_len=4,\n",
    "                norm_type='L',\n",
    "                activation='relu',\n",
    "                dropout=0.9,\n",
    "                n_block=2,\n",
    "                ff_dim=64,\n",
    "                target_slice=slice(20,21,None)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f9d4a67-5fde-43bd-a055-bece9f714f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSMixer(\n",
       "  (blocks): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (norm): LayerNorm((21,), eps=1e-05, elementwise_affine=True)\n",
       "      (temporal_linear): Sequential(\n",
       "        (0): Linear(in_features=21, out_features=336, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.9, inplace=False)\n",
       "      )\n",
       "      (feature_linear): Sequential(\n",
       "        (0): Linear(in_features=21, out_features=64, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.9, inplace=False)\n",
       "        (3): Linear(in_features=64, out_features=21, bias=True)\n",
       "        (4): Dropout(p=0.9, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (norm): LayerNorm((21,), eps=1e-05, elementwise_affine=True)\n",
       "      (temporal_linear): Sequential(\n",
       "        (0): Linear(in_features=21, out_features=336, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.9, inplace=False)\n",
       "      )\n",
       "      (feature_linear): Sequential(\n",
       "        (0): Linear(in_features=21, out_features=64, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.9, inplace=False)\n",
       "        (3): Linear(in_features=64, out_features=21, bias=True)\n",
       "        (4): Dropout(p=0.9, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): Linear(in_features=21, out_features=4, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "45f70f36-d874-4674-9f53-1ab21426f040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | blocks       | Sequential | 20.4 K\n",
      "1 | output_layer | Sequential | 88    \n",
      "--------------------------------------------\n",
      "20.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.5 K    Total params\n",
      "0.082     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|                                                                                                | 0/2 [00:00<?, ?it/s]336 21 21\n",
      "21 336\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (336) must match the size of tensor b (21) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training the model using PyTorch Lightning Trainer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Use gpus=0 if you don't have a GPU\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module_01\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    577\u001b[0m     ckpt_path,\n\u001b[1;32m    578\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    580\u001b[0m )\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 990\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    995\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1034\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1034\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1036\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1063\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1060\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    385\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[103], line 81\u001b[0m, in \u001b[0;36mTSMixer.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     80\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 81\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     target_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     83\u001b[0m     loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(y_hat, target_)\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[103], line 61\u001b[0m, in \u001b[0;36mTSMixer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrev_norm_inst:\n\u001b[1;32m     60\u001b[0m        x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrev_norm(x, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_slice:\n\u001b[1;32m     63\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_slice]\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_learning/pytorch_lightning/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[101], line 26\u001b[0m, in \u001b[0;36mResBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_linear(x)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_linear(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (336) must match the size of tensor b (21) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# Training the model using PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"mps\")  # Use gpus=0 if you don't have a GPU\n",
    "trainer.fit(model, datamodule=data_module_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076020e7-3686-4431-afd6-fc8fc8919bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa415b57-6d8b-4dee-aff7-0422c5ba8c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1271b14-9c46-4a20-af17-387ad439d37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5e744-85bb-435c-98c0-1034344f2aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef06da7-7c62-4758-84fd-f2ea96260a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleMLP(pl.LightningModule):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.fc1 = torch.nn.Linear(input_dim, input_dim)\n",
    "        self.fc2 = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= F.relu(self.fc1(x))\n",
    "        x= self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        contiguous_rows, last_four_rows = batch\n",
    "        contiguous_rows = contiguous_rows.view(contiguous_rows.size(0), -1)\n",
    "        last_four_rows = last_four_rows.view(last_four_rows.size(0), -1)\n",
    "        #nputs = torch.cat((contiguous_rows, last_four_rows), dim=1)\n",
    "        outputs = self(contiguous_rows)\n",
    "        loss = torch.nn.functional.mse_loss(outputs, last_four_rows)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "# Example usage:\n",
    "# Creating a sample DataFrame with 25 rows and 10 columns\n",
    "data = np.random.rand(25, 10)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Creating a DataExtractor instance\n",
    "data_extractor = DataExtractor(df)\n",
    "\n",
    "# Creating a LightningDataModule instance\n",
    "data_module = CustomDataModule(data_extractor)\n",
    "\n",
    "# Creating a SimpleMLP model\n",
    "input_dim = 100 #10 * 10 * 2  # Input dimension after concatenating contiguous_rows and last_four_rows\n",
    "output_dim = 40 # 10 * 4  # Output dimension (last_four_rows)\n",
    "model = SimpleMLP(input_dim, output_dim)\n",
    "\n",
    "# Training the model using PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"mps\")  # Use gpus=0 if you don't have a GPU\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eddb29d-7415-4044-8c9d-9b6c84119605",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72a19f-adc7-43ad-a71f-cdf98851db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff81cc5-ce98-4228-a96a-a1e69a126f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa1172-20bd-449f-8cb7-3385e5a15d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extractor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7385b7-48c5-4da0-b783-2f2fff4bae1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
